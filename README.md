# Musoassist-Chatbot
To develop a low cost integrated display technology that will convert a simple,manually operated gallery to a smart gallery containing a virtual explainer capable of explaining and operating the exhibit through a non-monotonic conversation with the visitor. This non-monotonic conversation is one of the most important features of the present work. This means the virtual explainer will redirect the conversation differently each time it is triggered with the same question or questions with a similar pattern. This will increase visitor engagement.Software architecture is the key to any design. This controls the total workflow of the system. Hence, understanding the software architecture will help us in understanding the working of the system. In this proposed system, primarily the visitor comes to the bot fitted at the entry of the gallery and asks for any demonstration. Here a speech-to-text conversion is needed for further processing in the system. As we know, creating a speech-to-text engine needs hours and hours of transcripted data and training [27]. But still, it is very difficult to get any optimized performance hence here we have used an open-source version of google’s web search API through the python library. Now it Is time for the selection of a Neural network-based architecture for matching the question with an answer. In literature [28] there are some advanced transformer-based bots available but we need the simplest possible solution that matches our requirement because we cannot afford many GPU based systems in the gallery. Hence we decided on the use of a keyword matching type bot as a solution.This type of system can easily be trained by anyone and runs on a CPU for both training and working. So using the converted text the bot matches any combination of matched keywords in the training output file, which returns a tag with the probability of a match. This is done by training a three-layer neural network. The first layer contained 128 neurons, the second layer contained 64 layers and the last layer had several tags predicted for output. In the
 figure below we have demonstrated the processing of a single question through
the 3-layer neural network to show how it works. Now using this predicted tag in the output layer we have played a video lip-synced with an answer corresponding to it instead of an animated model. We used this for cost-cutting and due to limited hardware. This lip-sync is done using the WEB2LIP, an open-source python library. As after playing any video, the last frame is held
by the player so normally it looks as if a virtual bot is doing the conversation with the visitor. If the selected TAG has any hardware or exhibit activation attached with it, this corresponding signal is sent to the exhibit client through the network. Figure 1 shows the flow diagram of the overall system described here. But while the pilot system was being evaluated by the visitor they found that the conversation with the chatbot without the context of the previous question makes it difficult to interact with it. For example, if the first question “Please give me a demo of Exhibit-1” and after giving a demo if in reply the bot asks “do you want anything more” the user naturally says only “Yes”. But whenever the context of the previous conversation is not kept, it is difficult to decode the answer only by “yes”. This problem forces us to rethink at this particular point. We decided to make this chatbot’s dialogue design closer to natural language. For this, we tried training the chatbot for situations where it needs to hold a multiple line conversation with the user in contrast to how we previously wanted it to simply answer one line questions and move on to the next. Figure 2 describes a part of the JSON file used for training that will help in understanding the organization of data in the file and the concept of context set or tag. A perfect scenario for context-based conversation is described with a knock-knock joke. Here, whenever the user asks the bot to tell him a joke, the chatbot starts with a knock-knock. The user’s second question that follows must be “Who’s there?”. Now we need the chatbot to remain in the context of the joke that it started and not take this “Who’s there” as an entirely new question. So using this context set we have made sure that the bot remains in context. But till now it’s only able to answer in a single pattern for a single type of question that initiates any context-based conversation. Hence we have named this type of bot a monotonic bot because if multiple visitors of a group ask the same question that carries a chain of context-based conversation its pattern of reply makes the conversation monotonic after a certain time. This is a limitation of the keyword search based bot we have selected for the limited availability of hardware. Hence we named it a non-monotonic type bot in this paper.Now to make it more natural we thought of introducing more variation in answer for repeating the same question that carries a chain of context-based conversation. This context-based conversation cannot be randomized simply by writing multiple preset answers based on the keyword, as it needs to hold the context of the prolonged conversation. For instance, when the user asks to tell a joke, we added three different answers to the “Who’s there” ie. We added three different knock-knock jokes that could be used as a response to one question. We made use of a master tag for “Knock-knock” and three sub-tags that held the three jokes respectively. We made use of the randomise function so that any one of the three jokes could be used by the chatbot. We encountered a problem that the probability of the three jokes being used was not equal. Therefore, the first joke was being used by the chatbot every time and the other two were being ignored. In order to make their probability equally likely, we have to optimize the training iterations. Initially, this was a manual optimization which proved to be very hectic later on. Hence in training MusoAssist: A Virtual Guide through the Museums Gallery 7 validation, we keep the number of iterations as a dynamic which is decided by enquiring a fixed question for which multiple tags with the same set of pattern exist. The training epoch runs till all the tags with the same pattern return with the same probability or within a margin of 0.05. Using this newtraining iteration and finally, we got the probability of all the three sub-tags to be about one-third. Consequently, we obtained a better result and the three jokes were used at random. This proposed bot is named a Random conversionChain (RCS) type bot in this work.
